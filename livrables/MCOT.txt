Postitionnement thématique :
Informatique (Informatique pratique), Sciences industrielles (Traitement du signal), Mathématiques (géométrie) 


Mots clés :
Modélisation 3D, Enveloppe visuelle, vision artificielle, detection de contour, segmentation d'image.
3D Modeling, Visual hull, computer vision, boundaries detection, image segmentation.


Bibliographie commentée :

La démocratisation de l'imprimerie 3D offre de nouvelles possibilités quant à la création d'objet. Mais avant de pouvoir imprimer un objet en 3D, il est nécéssaire de pouvoir le scanner, et de pouvoir le représenter en mémoire. Les différentes représentation en mémoire d'objets 3D comprennent principalement les représentation par voxels, et les représentations par polyhèdres[1']. Quant au scan, beaucoup de méthodes existent pour scanner un objet en 3D, mais seule la modélisation à partir de photographies est un moyen accessible à tous sans matériel particulier.
Cette méthode de modélisation se décline sous différentes formes, avec des performances variées. La première approche consiste à délimiter la silhouette de l'objet à scanner dans les photographies, puis à n'exploiter que ces silhouettes pour créer un modèle leur correspondant[1']. D'autres méthodes utilisent aussi la texture et les motifs dans l'image[2', 3'], et obtiennent des résultats excellents, mais sont plus complexes et nécessitent souvent des calculs plus longs, moins faciles à exécuter sur un smartphone que la méthode des silhouettes.
Cette méthode se divise principalement en trois parties : 
la détection de contour, qui s'attache à traiter une image afin de faire ressortir les contours des objets,
la segmentation de ces contours, qui transforme cette image de contours en un ensemble de segments devant délimiter la silhouette de l'objet sur la photographie,
et la reconstitution proprement dite, qui utilise les silhouettes pour créer le modèle 3D.

La détection de contour est basé sur le filtrage linéaire, c'est-à-dire le fait de substituer à un pixel une combinaison linéaire des pixels autour.
L'enjeu est de déterminer les filtres les plus efficaces pour isoler les contours. Une modélisation mathématique de ce qu'est un contour et du bruit que peut contenir une image s'impose alors afin de pouvoir optimiser les paramètres des filtres. C'est l'objet du travail de John Canny[1]. L'étude d'une image et de filtres se fait souvent dans le domaine fréquentielle et utilise les notions de convolution et de transformée de Fourier. Des méthodes ont été développées pour optimiser la conversion du domaine fréquentiel au domaine spatial[2]. Les techniques de filtrages introduites par J. Canny ont plus tard été appliquées à des images couleurs. l'idée principales est de dissocier la composante d'intensité lumineuse qui reste la meilleure indication des contour d'une image, de la composante chromatique, tout en faisant en sorte que celle-ci se rapproche le plus possible de la perception humaine des couleurs. Ainsi les méthode de filtrages sont appliquées séparéments au trois canaux de l'espace colorimétrique LAB[3,4]. A travers l'analyse fréquentielle, une composante de texture est également introduite[3,4]. Le problème est alors de savoir quels coefficients affecter aux réponses de ces composantes au filtrage afin d'obtenir les meilleurs contour possible. Les méthodes emergentes de machine learning peuvent être appliquées pour déterminer ces nombreux paramètres[4].

La segmentation d'image consiste séparer une image en plusieurs régions de manière à ce que tous les pixels d'une région soit le plus similaires possibles et le plus différents possible de ceux des autres régions. On espère ainsi séparer les différents éléments d'une image. Cela est possible par l'étude de la séparation optimale de graphe d'affinité utilisant des résultats d'algèbre linéaire[5]. Cependant, c'est  combinée à la détection de contour[4] et au machine learning que la segmentation est la meilleure.

La reconstitution à partir de silhouettes utilise un concept simple : si on connait la silhouette d'un objet vue depuis un certain point de vue, alors l'objet en question est inclus dans un cône ayant pour sommet le point focal du point de vue, et ayant pour forme la silhouette trouvée. En multipliant les photographies, on peut ainsi obtenir plusieurs silhouettes et donc plusieurs cône, et il suffit alors d'en faire une intersection pour obtenir un modèle 3D convenable[1']. On peut ensuite effectuer des traitements sur le modèle trouvé pour le rendre plus léger [9].


Problématique : 

La modélisation par utilisation de silhouette est légère et efficace, mais de nombreux paramètres et choix de méthodes peuvent affecter ses résultat. Il faut donc étudier leur influence sur le modèle obtenu.


Objectifs du travail :
Je me propose d'écrire un code en python qui permettent d'extraire d'une image la silhouette d'une objet et éventuellement des détails intérieurs à l'objet.
L'étude et la conception du code seront guidés par deux principes :  - la progression dans la relaxation des contraintes, d'une photographie sur fond blanc à une photographie sur fond quelconque, un éclairage de moins en moins bon, diminution de la qualité de la photo (définition, bruit). Cette progression dans le contraintes s'accompagnera d'une progression dans la complexité des méthodes employées - une étude de la complexité temporelle des méthodes utilisées, une réflexion sur la représentation en machine des données afin de garantir la rapidité des calculs, la recherche d'un compromis entre la précision du résultat et le temps nécessaire.


liste des références :
[4] J. Canny, A Computational Approach to Edge Detection
[5] J.W. Cooley and J.W. Tukey, An Algorithm for the Machine Calculation of Complex Fourier Series
[6] D.R. Martin, C.C. Fowlkes and J. Malik, Learning to Detect Natural Image Boundaries Using Local Brightness, Color, and Texture Cues
[7] M.R. Maire, Contour Detection and Image Segmentation
[8] J. Shi and J. Malik Normalized Cuts and Image Segmentation

[1]BAUMGART, B. 1974. Geometric modeling for computer vision. PhD thesis, Stanford University
[2]DEPTH FROM EDGE AND INTENSITY BASED STEREO, H. Harlyn Baker and Thomas 0. Binford
[3]Silhouette and Stereo Fusion for 3D Object Modeling, Carlos Hernandez Esteban and Francis Schmitt
[9]Decimation of Triangle Meshes, William J. Schroeder Jonathan A. Zarge William E. Lorensen


1'
2'
3'
1
2
3
4
5
4'
5'